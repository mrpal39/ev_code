# tc_zufang
一,项目背景
使用scrapy,redis, mongodb,django实现的一个分布式网络爬虫,底层存储mongodb,分布式使用redis实现,使用django可视化爬虫

这个项目是我学习了python爬虫一个项目总结，其中主要是对垂直搜索引擎中分布式网络爬虫的探索实现，暂时它包含针对58租房网和赶集租房网网站的spider， 可以将其网站所以地方的租房信息的爬取到本地，爬取的项目有标题，租金，地理位置等等项目，此个项目也是作为房源推荐系统的数据采集端，因为本机配置不太好，为了减轻压力，暂时没有加上下载图片pipeline.

二，项目功能与研究内容

1）基于scrapy+redis构建了一个分布式调度队列

将爬虫爬取到的项目详情请求url存储进redis存储队列，上一次请求结束后，再将下一次请求url推出队列给下载器进行爬取，并且多个爬虫可以共享整个请求队列

2）Docker管理分布式环境

更方便的管理爬虫生产环境

3）增量爬取


爬虫可以借助linux的crontab功能进行定时爬取，并且，爬取过的链接，将不会再进行爬取，主要是使用了redis组件的去重策略

4）爬虫防止被ban策略

网站具有一定的防爬措施，主要使用了一下策略来对爬虫进行防爬处理

（1）禁用cookie

（2）设置下载等待时间

（3）使用user_agent池，伪造浏览器信息

（4）使用多个代理ip（暂时没有实现）

5）断点续爬

爬虫遇到异常退出后，能够在上一次中断的队列中继续爬取，其实也使用了redis的一点小策略

6）文件存储

使用单个mongodb存储海量信息

mongodb集群存储（待实现）

7）爬虫调试策略

将系统log信息写到文件中

对重要的log信息(eg:drop item,success)采用彩色样式终端打印（待实现）

8）可视化爬虫数据

使用Django和highcharts

三，软件以及组件

编辑器：pycharm

mongodb可视化软件：MongoVUE

redis可视化软件：RedisDesktopManager
